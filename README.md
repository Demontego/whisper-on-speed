# Whisper on Speed

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–∞ –±–∞–∑–µ OpenAI Whisper —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU –∏ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
uv sync

# –ò–ª–∏ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
uv sync --dev
```

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from src.core.asr import ASRonSPEED
import librosa

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
asr = ASRonSPEED(model_id="openai/whisper-large-v3-turbo")

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
asr.warmup()

# –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
audio, _ = librosa.load("audio.wav", sr=16000)

# –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
chunks = asr.procces_audio(audio)
for chunk in chunks:
    print(f"{chunk.start_time:.2f}s - {chunk.end_time:.2f}s: {chunk.text}")

# –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
audio_files = [audio1, audio2, audio3]
batch_results = asr.process_batch(audio_files)
```

## –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU
- üì¶ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
- ‚è±Ô∏è –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
- üî• –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–µ–≤–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- üìä –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
uv run pytest

# –¢–æ–ª—å–∫–æ –±–µ–Ω—á–º–∞—Ä–∫–∏
uv run pytest -m benchmark
```

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.13+
- CUDA-—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è GPU (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- uv –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
