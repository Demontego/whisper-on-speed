{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demontego/whisper-on-speed/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from typing import Callable\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "from transformers.pipelines.automatic_speech_recognition import AutomaticSpeechRecognitionPipeline\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, attn_implementation='flash_attention_2',\n",
    ").eval().cuda()\n",
    "# model.generation_config.cache_implementation = \"static\"\n",
    "# model.generation_config.max_new_tokens = 324\n",
    "# model.forward = torch.compile(model.forward, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "# pipe = AutomaticSpeechRecognitionPipeline(\n",
    "#     model=model,\n",
    "#     tokenizer=processor.tokenizer,\n",
    "#     feature_extractor=processor.feature_extractor,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     stride_length_s=0.3,\n",
    "#     chunk_length_s=10,\n",
    "#     device=device,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, _ = librosa.load(\"/home/demontego/whisper/tests/test_data/output.wav\", sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178.432"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio) / 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def chunk_audio_with_overlap(\n",
    "    audio: np.ndarray,  # (n_samples,)\n",
    "    vad: torch.nn.Module,\n",
    "    get_speech_timestamps: Callable,\n",
    "    sr: int = 16000,\n",
    "    chunk_sec: int = 10,\n",
    "    overlap_sec: float = 0.5\n",
    ") -> np.ndarray[np.ndarray[np.float16]]:  # (N_chunks, chunk_len)\n",
    "    \"\"\"\n",
    "    Режет аудиомассив на куски с перекрытием и возвращает массив чанков.\n",
    "\n",
    "    :param audio: 1D np.ndarray аудиосигнала (float32 или int16)\n",
    "    :param sr: sample rate (по умолчанию 16kHz)\n",
    "    :param chunk_sec: длина каждого чанка в секундах\n",
    "    :param overlap_sec: длина перекрытия в секундах\n",
    "    :return: np.ndarray формы (N_chunks, chunk_len) с dtype float32\n",
    "    \"\"\"\n",
    "    if audio.ndim != 1:\n",
    "        raise ValueError(\"Input audio must be a 1D np.ndarray.\")\n",
    "\n",
    "    # Приводим к float32\n",
    "    audio = audio.astype(np.float16)\n",
    "\n",
    "    chunk_len = int(sr * chunk_sec)\n",
    "    step = int(chunk_len - sr * overlap_sec)\n",
    "    total_len = len(audio)\n",
    "\n",
    "    chunks = []\n",
    "    seconds = []\n",
    "\n",
    "    for start in range(0, total_len, step):\n",
    "        end = start + chunk_len\n",
    "        chunk = audio[start:end]\n",
    "        if len(chunk) < chunk_len:\n",
    "            chunk = np.pad(chunk, (0, chunk_len - len(chunk)))\n",
    "        speech_timestamps = get_speech_timestamps(chunk, vad, return_seconds=True)\n",
    "        sum_talk_seconds = sum(item['end'] - item['start'] for item in speech_timestamps)\n",
    "        if speech_timestamps and sum_talk_seconds > 1.0:\n",
    "            chunks.append(chunk)\n",
    "            seconds.append(start / sr)\n",
    "\n",
    "    return np.stack(chunks), seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/demontego/.cache/torch/hub/snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "vad, utils = torch.hub.load(\n",
    "    repo_or_dir='snakers4/silero-vad',\n",
    "    model='silero_vad',\n",
    "    force_reload=False,\n",
    "    onnx=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_audio, seconds = chunk_audio_with_overlap(audio, vad, utils[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_audio = np.vstack([chunked_audio] * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 160000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proccessed_audio = processor.feature_extractor(long_audio, sampling_rate=16000, return_tensors=\"pt\").input_features.to(torch.float16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 128, 3000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proccessed_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.generate(\n",
    "    input_features=proccessed_audio,\n",
    "    forced_decoder_ids=[[50258, 50360]],\n",
    "    length_penalty=1.0,\n",
    "    max_new_tokens=100,\n",
    "    num_beams=3,\n",
    "    condition_on_prev_tokens=True,\n",
    "    # compression_ratio_threshold=1.35,\n",
    "    temperature=0.1,\n",
    "    return_dict_in_generate=True,\n",
    "    return_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_whisper_output_proper(tokenizer_output, timestamps: list[float]) -> list[dict[str, float | str]]:\n",
    "    \"\"\"\n",
    "    Правильный способ обработки через tokenizer Whisper\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    for tokens, timestamp in zip(tokenizer_output.numpy(), timestamps):\n",
    "        # Используем встроенный метод декодирования\n",
    "        # Этот метод уже есть в вашем процессоре\n",
    "        decoded_segments, chunks = processor.tokenizer._decode_asr(\n",
    "            [{\"tokens\": [tokens]}], \n",
    "            return_language=False,\n",
    "            return_timestamps=True, \n",
    "            time_precision=0.02\n",
    "        )\n",
    "        for chunk in chunks['chunks']:\n",
    "            segments.append({\n",
    "                'start_time': chunk['timestamp'][0] + timestamp,\n",
    "                'end_time': min(chunk['timestamp'][1], 10.0) + timestamp,\n",
    "                'text': chunk['text'].strip()\n",
    "            })\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_time': 19.0,\n",
       "  'end_time': 29.0,\n",
       "  'text': 'Я читаю про дипсик и просто как индексфейли до этого не додумались просто'},\n",
       " {'start_time': 28.5,\n",
       "  'end_time': 38.5,\n",
       "  'text': 'просто нам прикольная прям архитектура что типа на поверхности что-то лежало там способ обучения типа он'},\n",
       " {'start_time': 38.0,\n",
       "  'end_time': 48.0,\n",
       "  'text': 'он много раз обсуждался, но почему-то я редко видел его в применении.'},\n",
       " {'start_time': 47.5, 'end_time': 48.42, 'text': 'в применении.'},\n",
       " {'start_time': 52.86,\n",
       "  'end_time': 54.88,\n",
       "  'text': 'А я знаю, почему они пошли'},\n",
       " {'start_time': 54.88, 'end_time': 57.5, 'text': 'по этому пути. Они начали'},\n",
       " {'start_time': 57.0,\n",
       "  'end_time': 64.26,\n",
       "  'text': 'начали обучать давно очень модель кодинга deepsick кодер не была лучшая модель вот и'},\n",
       " {'start_time': 64.26,\n",
       "  'end_time': 67.0,\n",
       "  'text': 'всех даже лучше чем сейчас gpt'},\n",
       " {'start_time': 66.5,\n",
       "  'end_time': 75.14,\n",
       "  'text': 'И они такие, надо еще лучше, и расширили пределы кодинга свою модель.'},\n",
       " {'start_time': 76.0,\n",
       "  'end_time': 86.0,\n",
       "  'text': 'гений считаю а чё там такое реинфорсмент тренинг как-то используется активно или'},\n",
       " {'start_time': 85.5,\n",
       "  'end_time': 95.5,\n",
       "  'text': 'активно или в чем-то да там rl активно используется и четыре этапа обучения идет но рель там эти по решению'},\n",
       " {'start_time': 95.0,\n",
       "  'end_time': 105.0,\n",
       "  'text': 'типа решает и 1 2 этап он реальный и типа возраст'},\n",
       " {'start_time': 104.5,\n",
       "  'end_time': 106.64,\n",
       "  'text': 'Нет модели вознаграждения.'},\n",
       " {'start_time': 108.0,\n",
       "  'end_time': 110.2,\n",
       "  'text': 'Есть только правильный и неправильный ответ.'},\n",
       " {'start_time': 111.62,\n",
       "  'end_time': 114.5,\n",
       "  'text': 'Типа всякие математические задачи.'},\n",
       " {'start_time': 114.0,\n",
       "  'end_time': 123.02,\n",
       "  'text': 'логические задачи по химии по биологии по физике вот что такое'},\n",
       " {'start_time': 123.5, 'end_time': 125.42, 'text': 'Это из науки.'},\n",
       " {'start_time': 129.36,\n",
       "  'end_time': 133.5,\n",
       "  'text': 'Это финальная стадия, правильный и неправильный ответ.'},\n",
       " {'start_time': 133.0,\n",
       "  'end_time': 143.0,\n",
       "  'text': 'Ну да, на финальной стадии у них есть ответ от модели, и его сравнивают с системой.'},\n",
       " {'start_time': 142.5,\n",
       "  'end_time': 150.36,\n",
       "  'text': 'с истиной насколько он близок вот это этот ответ которые самые близкие там по формуле'},\n",
       " {'start_time': 150.36,\n",
       "  'end_time': 152.5,\n",
       "  'text': 'расписывается чтобы он был наиболее'},\n",
       " {'start_time': 152.0, 'end_time': 153.46, 'text': 'наиболее вероятным.'},\n",
       " {'start_time': 154.5,\n",
       "  'end_time': 156.0,\n",
       "  'text': 'И дальше пропускают градиенты.'},\n",
       " {'start_time': 160.7, 'end_time': 162.0, 'text': 'А, то есть уже'},\n",
       " {'start_time': 161.5,\n",
       "  'end_time': 166.92,\n",
       "  'text': 'То есть уже потом обучают лосс и далее, уже дают функцию покеря.'},\n",
       " {'start_time': 167.52, 'end_time': 167.86, 'text': 'Ну да.'},\n",
       " {'start_time': 171.0,\n",
       "  'end_time': 179.0,\n",
       "  'text': 'Блин, ну, конечно, в этих всех темах, типа как оценить качество, да, насколько ответ...'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_whisper_output_proper(results, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = processor.batch_decode(\n",
    "    results,\n",
    "    decode_with_timestamps=True,\n",
    "    basic_normalize=True,\n",
    "    skip_special_tokens=True,\n",
    "    time_precision=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_whisper_timestamps_simple(text: str) -> list[tuple[float, float, str]]:\n",
    "    \"\"\"\n",
    "    Парсит простые случаи формата '<|start|> text <|end|>'\n",
    "    \"\"\"\n",
    "    pattern = r'<\\|(\\d+\\.?\\d*)\\|>\\s*(.*?)\\s*<\\|(\\d+\\.?\\d*)\\|>'\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    results = []\n",
    "    for match in matches:\n",
    "        start_time = float(match[0])\n",
    "        end_time = float(match[2])\n",
    "        content = match[1].strip()\n",
    "        results.append((start_time, end_time, content))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': [{'timestamp': (0.0, 2.06), 'text': ' you'},\n",
       "  {'timestamp': (0.0, 29.98), 'text': ' Продолжение следует...'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' Я читаю про дипсик и просто как индексфейли до этого не додумались просто'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' просто нам прикольная прям архитектура что типа на поверхности что-то лежало там способ обучения типа он'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' он много раз обсуждался, но почему-то я редко видел его в применении.'},\n",
       "  {'timestamp': (0.0, 0.92), 'text': ' в применении.'},\n",
       "  {'timestamp': (5.34, 7.38), 'text': ' А я знаю, почему они пошли'},\n",
       "  {'timestamp': (7.38, 10.0), 'text': ' по этому пути. Они начали'},\n",
       "  {'timestamp': (0.0, 7.26),\n",
       "   'text': ' начали обучать давно очень модель кодинга deepsick кодер не была лучшая модель вот и'},\n",
       "  {'timestamp': (7.26, 10.0), 'text': ' всех даже лучше чем сейчас гтт'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' и таки надо еще лучше и расширили пределы кодинга свою модель'},\n",
       "  {'timestamp': (0.0, 7.42),\n",
       "   'text': ' гений считаю а чё там такое reinforced'},\n",
       "  {'timestamp': (7.42, 10.0),\n",
       "   'text': ' тренинг как-то используется активно или'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' активно или в чем-то да там реле активно используется и четыре этапа обучения идет но рель там эти по решению'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' типа решает и первый второй этап он реальный и типа возраст'},\n",
       "  {'timestamp': (0.0, 2.14), 'text': ' Нет модели вознаграждения.'},\n",
       "  {'timestamp': (3.52, 5.7),\n",
       "   'text': ' Есть только правильный и неправильный ответ.'},\n",
       "  {'timestamp': (7.12, 10.0), 'text': ' Типа всякие математические задачи.'},\n",
       "  {'timestamp': (0.0, 9.02),\n",
       "   'text': ' логические задачи по химии по биологии по физике вот что такое'},\n",
       "  {'timestamp': (0.0, 1.92), 'text': ' Это из науки.'},\n",
       "  {'timestamp': (5.84, 10.0),\n",
       "   'text': ' Это финальная стадия, правильный и неправильный ответ.'},\n",
       "  {'timestamp': (0.0, 10.0),\n",
       "   'text': ' Ну да, на финальной стадии у них есть ответ от модели, и его сравнивают с системой.'},\n",
       "  {'timestamp': (0.0, 2.04), 'text': ' с истиной, насколько он близок.'},\n",
       "  {'timestamp': (4.02, 5.92), 'text': ' И тот ответ, который'},\n",
       "  {'timestamp': (5.92, 7.9), 'text': ' самый близкий, по формуле'},\n",
       "  {'timestamp': (7.9, 10.0), 'text': ' расписывается, чтобы он был наиболее'},\n",
       "  {'timestamp': (0.0, 1.44), 'text': ' наиболее вероятным.'},\n",
       "  {'timestamp': (2.3, 4.0), 'text': ' И дальше пропускают градиенты.'},\n",
       "  {'timestamp': (8.72, 10.0), 'text': ' А, то есть уже'},\n",
       "  {'timestamp': (0.0, 5.4),\n",
       "   'text': ' То есть уже потом обучают лосс и далее, уже дают функцию покеря.'},\n",
       "  {'timestamp': (6.04, 6.36), 'text': ' Ну да.'},\n",
       "  {'timestamp': (0.0, 8.0),\n",
       "   'text': ' Блин, ну, конечно, в этих всех темах, типа, как оценить качество, да, насколько ответ...'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded, chunks = processor.tokenizer._decode_asr(\n",
    "        [{\"tokens\": [results.flatten().numpy()]}], \n",
    "        return_timestamps=True, \n",
    "        return_language=False, \n",
    "        time_precision=0.02\n",
    "    )\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': [{'timestamp': (0.0, 1.0), 'text': ' пришел'},\n",
       "  {'timestamp': (1.0, 6.06), 'text': ' я читаю'},\n",
       "  {'timestamp': (6.06, 7.82), 'text': ' про дипсик и просто'},\n",
       "  {'timestamp': (7.82, 10.0), 'text': ' как интересно'}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe(audio, generate_kwargs=generate_kwargs, return_timestamps=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demontego/whisper-on-speed/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/demontego/.cache/torch/hub/snakers4_silero-vad_master\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "from src.core.pipe import Pipe\n",
    "from src.core.config import ASRConfig, AudioProcessorConfig\n",
    "\n",
    "config_asr = ASRConfig(model_id='openai/whisper-large-v3-turbo')\n",
    "config_processor = AudioProcessorConfig()\n",
    "pipe = Pipe(config_asr, config_processor)\n",
    "\n",
    "pipe.warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, _ = librosa.load(\"/home/demontego/whisper/tests/test_data/output.wav\", sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe([audio])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Replica(text='Продолжение следует...', start_time=9.7, end_time=19.7),\n",
       " Replica(text='я читаю про дипсик и просто как индекс файлы до этого не додумались просто', start_time=19.4, end_time=29.4),\n",
       " Replica(text='Там прикольная прям архитектура, что на поверхности что-то лежало.', start_time=29.1, end_time=35.18),\n",
       " Replica(text='Там способ обучения, типа он...', start_time=35.980000000000004, end_time=39.1),\n",
       " Replica(text='много раз обсуждался', start_time=38.8, end_time=43.44),\n",
       " Replica(text='но почему-то', start_time=43.44, end_time=46.22),\n",
       " Replica(text='я редко видел его в применении', start_time=46.22, end_time=48.699999999999996),\n",
       " Replica(text='Я знаю, почему они пошли', start_time=48.5, end_time=54.88),\n",
       " Replica(text='по этому пути. Они', start_time=54.88, end_time=56.8),\n",
       " Replica(text='начали обучать давно', start_time=56.8, end_time=58.5),\n",
       " Replica(text='очень модель кодинга deepsick кодер не была лучшая модель вот и всех даже лучше чем сейчас гтт и надо', start_time=58.2, end_time=68.2),\n",
       " Replica(text='надо еще лучше и расширили', start_time=67.9, end_time=70.2),\n",
       " Replica(text='пределы', start_time=70.2, end_time=72.4),\n",
       " Replica(text='кодинга', start_time=72.4, end_time=72.98),\n",
       " Replica(text='свою модель.', start_time=72.98, end_time=75.14),\n",
       " Replica(text='Угу.', start_time=77.14, end_time=77.9),\n",
       " Replica(text='гениях,', start_time=77.6, end_time=79.97999999999999),\n",
       " Replica(text='считаю.', start_time=79.97999999999999, end_time=80.6),\n",
       " Replica(text='А что там такое? Reinforcement', start_time=81.32, end_time=83.5),\n",
       " Replica(text='learning как-то используется активно', start_time=83.5, end_time=85.88),\n",
       " Replica(text='или в чем там? Да, там RL,', start_time=85.88, end_time=87.6),\n",
       " Replica(text='реле активно используется и там четыре этапа обучения идет вот номер эль там типа решает', start_time=87.3, end_time=95.92),\n",
       " Replica(text='и первый второй этап он реальный и типа нет модели вознаграждения', start_time=97.0, end_time=107.0),\n",
       " Replica(text='есть только', start_time=106.7, end_time=108.64),\n",
       " Replica(text='правильный и неправильный ответ', start_time=108.64, end_time=110.22),\n",
       " Replica(text='вот', start_time=110.22, end_time=111.34),\n",
       " Replica(text='всякие математические задачи', start_time=111.34, end_time=113.92),\n",
       " Replica(text='вот', start_time=113.92, end_time=116.7),\n",
       " Replica(text='логические задачи по химии по биологии по физике вот что такое ты науки', start_time=116.4, end_time=126.4),\n",
       " Replica(text='это', start_time=126.1, end_time=128.1),\n",
       " Replica(text='финальная', start_time=128.1, end_time=130.1),\n",
       " Replica(text='стадия', start_time=130.1, end_time=132.1),\n",
       " Replica(text='правильный ответ', start_time=132.1, end_time=134.1),\n",
       " Replica(text='ну да', start_time=134.1, end_time=136.1),\n",
       " Replica(text='стадии у них типа нет национальная стадия у них есть типа ответ от модели и его сравнивают с истинным', start_time=135.8, end_time=143.24),\n",
       " Replica(text='насколько он близок вот', start_time=143.24, end_time=145.8),\n",
       " Replica(text='И тот ответ, который самый близкий, по формуле расписывается, чтобы он был наиболее вероятным.', start_time=145.5, end_time=153.46),\n",
       " Replica(text='И дальше пропускают границу.', start_time=154.56, end_time=155.5),\n",
       " Replica(text='а то есть уже потом обучают типа вот это лосс и далее', start_time=155.2, end_time=165.2),\n",
       " Replica(text='далее, ожидает, что он потерь.', start_time=164.9, end_time=166.84),\n",
       " Replica(text='Ну да.', start_time=167.54, end_time=167.86),\n",
       " Replica(text='Блин, ну, конечно, в этих всех темах', start_time=172.9, end_time=174.9),\n",
       " Replica(text='темах и по как оценить качество да насколько ответ', start_time=174.6, end_time=178.42)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
